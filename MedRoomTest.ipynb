{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Score de semelhança entre frases.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z2jqqYDKpKUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Objetivo**\n",
        "\n",
        "---\n",
        "\n",
        "Neste pequeno projeto o objetivo é mostrar a similaridade entre frases. Para isso, usarei um modelo pré-treinado de Processamento de Linguagem Natural (NPL), **BERT**."
      ],
      "metadata": {
        "id": "aav5nNdR-C34"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "### **Dados**\n",
        "\n",
        "---\n",
        "\n",
        "Dada a seguinte frase original:\n",
        "\n",
        "*Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?*\n",
        "\n",
        "Temos 3 frases  que iremos comparar com a frase original e retornar um score de semelhança entre comparativa x original.\n",
        "\n",
        "*   *De acordo com a escala de dor ali na parede, qual valor você acha que mais representa a sua dor?*\n",
        "*   *De 0 a 10, qual o nível de intensidade da sua dor atualmente?*\t\n",
        "*   *Qual a intensidade da sua dor?*"
      ],
      "metadata": {
        "id": "iTpD8JYS-NW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo BERT**\n",
        "\n",
        "---\n",
        "\n",
        "Instalação da biblioteca Hugging Face Transformers com a implementação do BERT"
      ],
      "metadata": {
        "id": "d58b_sBJ9oER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# transformers\n",
        "\n",
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "nGMvjYJoC04J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, criamos uma função que recebe duas frases, faz a comparação e retorna o score de similaridade entre elas utilizando o modelo BERT. A função emprega o tokenizer e converte as frases em vetores numéricos aceitos pelo modelo BERT. Depois, as frases são submetidas ao modelo, obtendo uma saída numérica para cada uma. Então, a função calcula o score de similaridade entre as saídas."
      ],
      "metadata": {
        "id": "svm8pOMUGjha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# bibliotecas necessárias para utilizar o modelo BERT\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForPreTraining, AutoModel\n",
        "import torch\n",
        "\n",
        "# modelo e o tokenizer pré-treinado do BERT para português\n",
        "\n",
        "model = AutoModelForPreTraining.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')\n",
        "\n",
        "# Função score\n",
        "\n",
        "def score_similaridade(frase1, frase2):\n",
        "    # Token das frases\n",
        "    token_frase1 = tokenizer(frase1, return_tensors=\"pt\")\n",
        "    token_frase2 = tokenizer(frase2, return_tensors=\"pt\")\n",
        "    \n",
        "    # Passando pelo BERT\n",
        "    with torch.no_grad():\n",
        "        saida1 = model(**token_frase1)[1].numpy()\n",
        "        saida2 = model(**token_frase2)[1].numpy()\n",
        "    \n",
        "    # Score de similaridade entre as duas saídas\n",
        "    score = (saida1 @ saida2.T).item()\n",
        "    return score"
      ],
      "metadata": {
        "id": "BeEraLMBGx39"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### **Comparação das frases**\n",
        "---\n",
        "Agora, é possível comparar as frases com a original."
      ],
      "metadata": {
        "id": "aAl8y-uJMlVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Frase original\n",
        "original = \"Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?\"\n",
        "\n",
        "# Frases comparativas\n",
        "comparativa1 = \"De acordo com a escala de dor ali na parede, qual valor você acha que mais representa a sua dor?\"\n",
        "comparativa2 = \"De 0 a 10, qual o nível de intensidade da sua dor atualmente?\"\n",
        "comparativa3 = \"Qual a intensidade da sua dor?\"\n",
        "\n",
        "# Calculando os scores de similaridade\n",
        "score1 = score_similaridade(original, comparativa1)\n",
        "score2 = score_similaridade(original, comparativa2)\n",
        "score3 = score_similaridade(original, comparativa3)\n",
        "\n",
        "print(\"Score de similaridade da frase 1:\", score1)\n",
        "print(\"Score de similaridade da frase 2:\", score2)\n",
        "print(\"Score de similaridade da frase 3:\", score3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCS6DOaONikB",
        "outputId": "99744b42-4ba9-4ee8-8c4f-f76d940fad77"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score de similaridade da frase 1: 0.4671139717102051\n",
            "Score de similaridade da frase 2: 0.28231847286224365\n",
            "Score de similaridade da frase 3: 0.34338945150375366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## **Resultados**\n",
        "---\n",
        "Como podemos ver, o modelo nos dá três saídas, uma para cada comparação feita. \n",
        "\n",
        "Veja como cada uma se saiu em relaçâo a frase \"Olhando para a escala na parede, qual valor indicaria melhor a sua dor hoje?\"\n",
        "\n",
        "*   \"De acordo com a escala de dor ali na parede, qual valor você acha que mais representa a sua dor?\"\n",
        "    \n",
        "    - Obteve um score de 0.467113, ou seja, 46,71% de similaridade.\n",
        "\n",
        "\n",
        "*   \"De 0 a 10, qual o nível de intensidade da sua dor atualmente?\"\n",
        "    \n",
        "    - Obteve um score de 0.282318, ou seja, 28,23% de similaridade.\n",
        "\n",
        "\n",
        "*   \"Qual a intensidade da sua dor?\"\n",
        "\n",
        "    - Obteve um score de 0.343389, ou seja, 34,33% de similaridade.\n",
        "\n",
        "**Com isso, a conclusão é que a frase 1 é a que mais se assemelha a frase original.**\n",
        "\n"
      ],
      "metadata": {
        "id": "EJiSrIHI_mno"
      }
    }
  ]
}